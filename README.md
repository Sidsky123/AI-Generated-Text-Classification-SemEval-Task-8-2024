# AI-Generated-Text-Classification-SemEval-Task-8-2024
This repository contains code to demonstrate solutions to SEMEVAL Task 8 2024 - https://semeval.github.io/SemEval2024/tasks.html

Question for the Given Assignment - 
In this assignment, you will classify texts into having been generated by a Large Language Model (LLM) or not.
The data to use is part of the SemEval 2024 Task 8, (DATASET LINK) - https://github.com/mbzuai-nlp/SemEval2024-task8 Multidomain, Multimodel and Multilingual Machine-Generated Text Detection.

We will focus only on Subtask A. Binary Human-Written vs. Machine-Generated Text Classification: Given a full text, determine whether it is human-written or machine-generated. Use only the data for subtask A: monolingual, that is only the English texts. Please ignore the multilingual data.
Download the training data from the Google drive link for Task A, https://drive.google.com/drive/folders/1CAbb3DjrOPBNm0ozVBfhvrEh9P9rAppcthe file subtaskA_train_monolingual.jsonl  (there is a dev data file there, you can use it or not, it is optional). Subtask A (monolingual) contains 119,757 texts for training and 5,000 as dev data, with labels, in JSON format, for each object:

{

  id -> identifier of the example,

  label -> label (human text: 0, machine text: 1,),

  text -> text generated by a machine or written by a human,

  model -> model that generated the data,

  source -> source (Wikipedia, Wikihow, Peerread, Reddit, Arxiv)  on English or language (Arabic, Russian, Chinese, Indonesian, Urdu, Bulgarian, German)

}

The test data is available in the file subtaskA_monolingual.jsonl

At https://drive.google.com/drive/folders/10DKtClzkwIIAatzHBWXZXuQNID-DNGSG

as well as the expected solution (gold standard) in a file with the same name

https://drive.google.com/drive/folders/13aFJK4UyY3Gxg_2ceEAWfJvzopB1vkPc

Your system should produce a prediction file, one single JSONL file for all the texts in the test data. The entry for each text must include the fields "id" and "label".

There is a format checker if you want to verify that your prediction file complies with the expected format. It is located in the format_checker module in the subtask A directory.
