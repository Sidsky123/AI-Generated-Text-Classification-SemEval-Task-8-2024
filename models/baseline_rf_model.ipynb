{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7930375,"sourceType":"datasetVersion","datasetId":4656808}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-24T15:00:12.360533Z","iopub.execute_input":"2024-03-24T15:00:12.361463Z","iopub.status.idle":"2024-03-24T15:00:24.930308Z","shell.execute_reply.started":"2024-03-24T15:00:12.361427Z","shell.execute_reply":"2024-03-24T15:00:24.929293Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.21.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\nimport pandas as pd\nimport evaluate\nimport numpy as np\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer, set_seed\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom scipy.special import softmax\nimport argparse\nimport logging\n\ndef preprocess_function(examples, **fn_kwargs):\n    return fn_kwargs['tokenizer'](examples[\"text\"], truncation=True)\n\n\ndef get_data(train_path, test_path, random_seed):\n    \"\"\"\n    function to read dataframe with columns\n    \"\"\"\n\n    train_df = pd.read_json(train_path, lines=True)\n    test_df = pd.read_json(test_path, lines=True)\n    \n    train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=random_seed)\n\n    return train_df, val_df, test_df\n\ndef compute_metrics(eval_pred):\n\n    f1_metric = evaluate.load(\"f1\")\n\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    \n    results = {}\n    results.update(f1_metric.compute(predictions=predictions, references = labels, average=\"micro\"))\n\n    return results\n\n\ndef fine_tune(train_df, valid_df, checkpoints_path, id2label, label2id, model):\n\n    # pandas dataframe to huggingface Dataset\n    train_dataset = Dataset.from_pandas(train_df)\n    valid_dataset = Dataset.from_pandas(valid_df)\n    \n    # get tokenizer and model from huggingface\n    tokenizer = AutoTokenizer.from_pretrained(model)     # put your model here\n    model = AutoModelForSequenceClassification.from_pretrained(\n       model, num_labels=len(label2id), id2label=id2label, label2id=label2id    # put your model here\n    )\n    \n    # tokenize data for train/valid\n    tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True, fn_kwargs={'tokenizer': tokenizer})\n    tokenized_valid_dataset = valid_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n    \n\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n\n    # create Trainer \n    training_args = TrainingArguments(\n        output_dir=checkpoints_path,\n        learning_rate=2e-5,\n        per_device_train_batch_size=16,\n        per_device_eval_batch_size=16,\n        num_train_epochs=3,\n        weight_decay=0.01,\n        evaluation_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n    )\n\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_train_dataset,\n        eval_dataset=tokenized_valid_dataset,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n\n    trainer.train()\n\n    # save best model\n    best_model_path = checkpoints_path+'/best/'\n    \n    if not os.path.exists(best_model_path):\n        os.makedirs(best_model_path)\n    \n\n    trainer.save_model(best_model_path)\n\n\ndef test(test_df, model_path, id2label, label2id):\n    \n    # load tokenizer from saved model \n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n\n    # load best model\n    model = AutoModelForSequenceClassification.from_pretrained(\n       model_path, num_labels=len(label2id), id2label=id2label, label2id=label2id\n    )\n            \n    test_dataset = Dataset.from_pandas(test_df)\n\n    tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n    # create Trainer\n    trainer = Trainer(\n        model=model,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n    # get logits from predictions and evaluate results using classification report\n    predictions = trainer.predict(tokenized_test_dataset)\n    prob_pred = softmax(predictions.predictions, axis=-1)\n    preds = np.argmax(predictions.predictions, axis=-1)\n    metric = evaluate.load(\"bstrai/classification_report\")\n    results = metric.compute(predictions=preds, references=predictions.label_ids)\n    \n    # return dictionary of classification report\n    return results, preds\n\n\nif __name__ == '__main__':\n\n    random_seed = 0\n    train_path =  \"/kaggle/input/text-dataset/subtaskA_train_monolingual.jsonl\" # For example 'subtaskA_train_multilingual.jsonl'\n    test_path =  \"/kaggle/input/text-dataset/subtaskA_monolingual.jsonl\" # For example 'subtaskA_test_multilingual.jsonl'\n    model =  \"xlm-roberta-base\" # For example 'xlm-roberta-base'\n    subtask =  'A' # For example 'A'\n    prediction_path = 'subtaskA_predictions.jsonl' # For example subtaskB_predictions.jsonl\n\n    if not os.path.exists(train_path):\n        logging.error(\"File doesnt exists: {}\".format(train_path))\n        raise ValueError(\"File doesnt exists: {}\".format(train_path))\n    \n    if not os.path.exists(test_path):\n        logging.error(\"File doesnt exists: {}\".format(train_path))\n        raise ValueError(\"File doesnt exists: {}\".format(train_path))\n    \n\n    if subtask == 'A':\n        id2label = {0: \"human\", 1: \"machine\"}\n        label2id = {\"human\": 0, \"machine\": 1}\n    elif subtask == 'B':\n        id2label = {0: 'human', 1: 'chatGPT', 2: 'cohere', 3: 'davinci', 4: 'bloomz', 5: 'dolly'}\n        label2id = {'human': 0, 'chatGPT': 1,'cohere': 2, 'davinci': 3, 'bloomz': 4, 'dolly': 5}\n    else:\n        logging.error(\"Wrong subtask: {}. It should be A or B\".format(train_path))\n        raise ValueError(\"Wrong subtask: {}. It should be A or B\".format(train_path))\n\n    set_seed(random_seed)\n\n    #get data for train/dev/test sets\n    train_df, valid_df, test_df = get_data(train_path, test_path, random_seed)\n    \n    # train detector model\n    fine_tune(train_df, valid_df, f\"{model}/subtask{subtask}/{random_seed}\", id2label, label2id, model)\n\n    # test detector model\n    results, predictions = test(test_df, f\"{model}/subtask{subtask}/{random_seed}/best/\", id2label, label2id)\n    \n    logging.info(results)\n    predictions_df = pd.DataFrame({'id': test_df['id'], 'label': predictions})\n    predictions_df.to_json(prediction_path, lines=True, orient='records')","metadata":{"execution":{"iopub.status.busy":"2024-03-23T21:05:49.888534Z","iopub.execute_input":"2024-03-23T21:05:49.888870Z","iopub.status.idle":"2024-03-24T02:06:41.030960Z","shell.execute_reply.started":"2024-03-23T21:05:49.888845Z","shell.execute_reply":"2024-03-24T02:06:41.029245Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb35ebb2fb444c7d8c6d304ecfb2c5fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cd8f23924b84976876aa21a30957283"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac834ef71f4d4304993b42152659a5a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90efa57ac3264297a9bc8572180d8df8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e03814914f4cf1b2db265efb169366"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/96 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab032986e1f143c1a0af70ac64cb17d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/24 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6a801e6c7f429982db51b4217e7a13"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240323_211052-w79w3udy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/myteam-29/huggingface/runs/w79w3udy' target=\"_blank\">dry-wave-2</a></strong> to <a href='https://wandb.ai/myteam-29/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/myteam-29/huggingface' target=\"_blank\">https://wandb.ai/myteam-29/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/myteam-29/huggingface/runs/w79w3udy' target=\"_blank\">https://wandb.ai/myteam-29/huggingface/runs/w79w3udy</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='17964' max='17964' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [17964/17964 4:44:28, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.095400</td>\n      <td>0.303350</td>\n      <td>0.928732</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.058600</td>\n      <td>0.212400</td>\n      <td>0.956204</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.024100</td>\n      <td>0.365910</td>\n      <td>0.940882</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eea2bd94c52d445caf10fa6fa9edd4b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/35 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d41d9f2f9f4436d99af85021c6de768"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2982c92a5854292b832f642268ac7eb"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/evaluate/module.py:513\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, column \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_nested_string_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_feature_format[key], column[\u001b[38;5;241m0\u001b[39m])\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 166\u001b[0m\n\u001b[1;32m    163\u001b[0m fine_tune(train_df, valid_df, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/subtask\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_seed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, id2label, label2id, model)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# test detector model\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m results, predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/subtask\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubtask\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/best/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid2label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel2id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(results)\n\u001b[1;32m    169\u001b[0m predictions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions})\n","Cell \u001b[0;32mIn[4], line 123\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(test_df, model_path, id2label, label2id)\u001b[0m\n\u001b[1;32m    121\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions\u001b[38;5;241m.\u001b[39mpredictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    122\u001b[0m metric \u001b[38;5;241m=\u001b[39m evaluate\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbstrai/classification_report\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 123\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# return dictionary of classification report\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results, preds\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/evaluate/module.py:450\u001b[0m, in \u001b[0;36mEvaluationModule.compute\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m compute_kwargs \u001b[38;5;241m=\u001b[39m {k: kwargs[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_names()}\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finalize()\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/evaluate/module.py:518\u001b[0m, in \u001b[0;36mEvaluationModule.add_batch\u001b[0;34m(self, predictions, references, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mwrite_batch(batch)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    519\u001b[0m         col0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))\n\u001b[1;32m    520\u001b[0m         bad_col \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m batch \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch[c]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[col0])][\u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/evaluate/module.py:518\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mwrite_batch(batch)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (pa\u001b[38;5;241m.\u001b[39mArrowInvalid, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch\u001b[38;5;241m.\u001b[39mvalues()))) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m batch):\n\u001b[1;32m    519\u001b[0m         col0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))\n\u001b[1;32m    520\u001b[0m         bad_col \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m batch \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch[c]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[col0])][\u001b[38;5;241m0\u001b[39m]\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"],"ename":"TypeError","evalue":"object of type 'NoneType' has no len()","output_type":"error"}]},{"cell_type":"code","source":"!pip install jsonlines","metadata":{"execution":{"iopub.status.busy":"2024-03-24T18:31:24.548326Z","iopub.execute_input":"2024-03-24T18:31:24.548627Z","iopub.status.idle":"2024-03-24T18:31:37.516535Z","shell.execute_reply.started":"2024-03-24T18:31:24.548600Z","shell.execute_reply":"2024-03-24T18:31:37.515411Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting jsonlines\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines) (23.2.0)\nDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nInstalling collected packages: jsonlines\nSuccessfully installed jsonlines-4.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import jsonlines\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\n\n# Load your dataset\ndef load_data(file_path):\n    texts, labels = [], []\n    with jsonlines.open(file_path, mode='r') as reader:\n        for obj in reader:\n            texts.append(obj['text'])\n            # Assuming the label for human-written is 'human' and for ChatGPT-written is 'chatgpt'\n            labels.append(obj['label'])\n    return texts, labels\n\n# Preprocess and Vectorize the text data\ndef preprocess_and_vectorize(texts):\n    vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_features=10000)\n    features = vectorizer.fit_transform(texts)\n    return features, vectorizer\n\ndef test_preprocess_and_vectorize(texts, vectorizer):\n    return vectorizer.transform(texts)\n\n# Main function to load data, train and evaluate the model\ndef train(jsonl_file_path, test_file_path):\n    # Load the dataset\n    texts, labels = load_data(jsonl_file_path)\n    test_text, test_labels = load_data(test_file_path)\n    \n    # Preprocess and vectorize text data\n    X, vectorizer = preprocess_and_vectorize(texts)\n    y = pd.Series(labels)\n    \n    \n    \n    # Split the dataset into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    X_test_gold = test_preprocess_and_vectorize(test_text,vectorizer)\n    y_test_gold = pd.Series(test_labels)\n    \n    # Initialize and train a logistic regression classifier\n    classifier = RandomForestClassifier()\n    classifier.fit(X_train, y_train)\n    \n    # Make predictions on the test set\n    predictions = classifier.predict(X_test)\n    \n    predictions_gold = classifier.predict(X_test_gold)\n    \n    # Evaluate the classifier\n    print(f\"Training Accuracy: {accuracy_score(y_test, predictions)}\")\n    print(f\"Training Micro F1 Score:{f1_score(y_test, predictions, average='micro')} \")\n    print(\"\\nTraining Classification Report:\")\n    print(classification_report(y_test, predictions))\n    print(f\"\\nTraining Confusion Matrix:\")\n    print(confusion_matrix(y_test, predictions))\n    \n    print(f\"\\n\\nTesting Gold Accuracy: {accuracy_score(y_test_gold, predictions_gold)}\")\n    print(f\"Testing Gold Micro F1 Score:{f1_score(y_test_gold, predictions_gold, average='micro')} \")\n    print(\"\\Testing Gold Classification Report:\")\n    print(classification_report(y_test_gold, predictions_gold))\n    print(f\"\\Testing Gold Confusion Matrix:\")\n    print(confusion_matrix(y_test_gold, predictions_gold))\n    \n    return classifier, test_text, X_test\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T19:27:36.980884Z","iopub.execute_input":"2024-03-24T19:27:36.981522Z","iopub.status.idle":"2024-03-24T19:27:36.999669Z","shell.execute_reply.started":"2024-03-24T19:27:36.981479Z","shell.execute_reply":"2024-03-24T19:27:36.998649Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"jsonl_file_path = '/kaggle/input/text-dataset/subtaskA_train_monolingual.jsonl'  # Update this path\nclassifier, test_text, X_test = train(jsonl_file_path, \"/kaggle/input/text-dataset/subtaskA_monolingual_gold.jsonl\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T19:27:39.908621Z","iopub.execute_input":"2024-03-24T19:27:39.908988Z","iopub.status.idle":"2024-03-24T19:39:08.798829Z","shell.execute_reply.started":"2024-03-24T19:27:39.908947Z","shell.execute_reply":"2024-03-24T19:39:08.797793Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Training Accuracy: 0.8772127588510354\nTraining Micro F1 Score:0.8772127588510354 \n\nTraining Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.85      0.93      0.89     12496\n           1       0.91      0.82      0.87     11456\n\n    accuracy                           0.88     23952\n   macro avg       0.88      0.87      0.88     23952\nweighted avg       0.88      0.88      0.88     23952\n\n\nTraining Confusion Matrix:\n[[11585   911]\n [ 2030  9426]]\n\n\nTesting Gold Accuracy: 0.8691935107376284\nTesting Gold Micro F1 Score:0.8691935107376284 \n\\Testing Gold Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.83      0.91      0.87     16272\n           1       0.91      0.83      0.87     18000\n\n    accuracy                           0.87     34272\n   macro avg       0.87      0.87      0.87     34272\nweighted avg       0.87      0.87      0.87     34272\n\n\\Testing Gold Confusion Matrix:\n[[14772  1500]\n [ 2983 15017]]\n","output_type":"stream"}]},{"cell_type":"code","source":"data = [{\"text\" : test_text[index], \"label\" : classifier.predict(encodings).tolist(), 'id':index} for index, encodings in enumerate(X_test)]\n    \nwith jsonlines.open('prediction.json', mode='w') as writer:\n    for entry in data:\n        writer.write(entry)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T19:39:08.804748Z","iopub.execute_input":"2024-03-24T19:39:08.805048Z","iopub.status.idle":"2024-03-24T19:41:50.587285Z","shell.execute_reply.started":"2024-03-24T19:39:08.805023Z","shell.execute_reply":"2024-03-24T19:41:50.586415Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-03-24T19:26:17.736083Z","iopub.execute_input":"2024-03-24T19:26:17.736380Z","iopub.status.idle":"2024-03-24T19:26:18.858415Z","shell.execute_reply.started":"2024-03-24T19:26:17.736354Z","shell.execute_reply":"2024-03-24T19:26:18.857347Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}