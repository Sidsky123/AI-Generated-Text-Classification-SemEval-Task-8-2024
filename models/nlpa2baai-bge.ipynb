{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7926296,"sourceType":"datasetVersion","datasetId":4658363},{"sourceId":7931894,"sourceType":"datasetVersion","datasetId":4662372},{"sourceId":7933142,"sourceType":"datasetVersion","datasetId":4663230}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    print(\"GPU is available\")\nelse:\n    print(\"GPU is not available\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:52:59.076968Z","iopub.execute_input":"2024-03-24T21:52:59.077535Z","iopub.status.idle":"2024-03-24T21:53:02.883583Z","shell.execute_reply.started":"2024-03-24T21:52:59.077501Z","shell.execute_reply":"2024-03-24T21:53:02.882597Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"GPU is available\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install evaluate ","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:53:02.885124Z","iopub.execute_input":"2024-03-24T21:53:02.885514Z","iopub.status.idle":"2024-03-24T21:53:17.899007Z","shell.execute_reply.started":"2024-03-24T21:53:02.885488Z","shell.execute_reply":"2024-03-24T21:53:17.897686Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.21.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.get_device_name(0)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:53:17.900882Z","iopub.execute_input":"2024-03-24T21:53:17.901243Z","iopub.status.idle":"2024-03-24T21:53:17.933278Z","shell.execute_reply.started":"2024-03-24T21:53:17.901213Z","shell.execute_reply":"2024-03-24T21:53:17.932307Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'Tesla P100-PCIE-16GB'"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset\nimport pandas as pd\nimport evaluate\nimport numpy as np\nfrom transformers import (\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding,\n    AutoTokenizer,\n    set_seed,\n    LlamaTokenizer,\n    LlamaForSequenceClassification,\n    ElectraForSequenceClassification,\n    ElectraTokenizerFast,\n    ElectraModel\n)\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom scipy.special import softmax\nimport argparse\nimport logging","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:53:17.936191Z","iopub.execute_input":"2024-03-24T21:53:17.936567Z","iopub.status.idle":"2024-03-24T21:53:37.414552Z","shell.execute_reply.started":"2024-03-24T21:53:17.936533Z","shell.execute_reply":"2024-03-24T21:53:37.413698Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-03-24 21:53:23.452599: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-24 21:53:23.452717: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-24 21:53:23.599063: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\ndata = pd.read_json('/kaggle/input/subtaska/subtaskA_train_monolingual.jsonl', lines = True)\ndf = data[['text','label']]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:53:37.415733Z","iopub.execute_input":"2024-03-24T21:53:37.416404Z","iopub.status.idle":"2024-03-24T21:53:43.507869Z","shell.execute_reply.started":"2024-03-24T21:53:37.416374Z","shell.execute_reply":"2024-03-24T21:53:43.506997Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df = df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:53:43.509088Z","iopub.execute_input":"2024-03-24T21:53:43.509421Z","iopub.status.idle":"2024-03-24T21:53:43.519325Z","shell.execute_reply.started":"2024-03-24T21:53:43.509395Z","shell.execute_reply":"2024-03-24T21:53:43.518358Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\nhuggingdata = Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:53:44.301254Z","iopub.execute_input":"2024-03-24T21:53:44.301535Z","iopub.status.idle":"2024-03-24T21:53:45.224149Z","shell.execute_reply.started":"2024-03-24T21:53:44.301512Z","shell.execute_reply":"2024-03-24T21:53:45.223258Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"huggingdata ","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:53:45.225427Z","iopub.execute_input":"2024-03-24T21:53:45.225742Z","iopub.status.idle":"2024-03-24T21:53:45.232511Z","shell.execute_reply.started":"2024-03-24T21:53:45.225716Z","shell.execute_reply":"2024-03-24T21:53:45.231440Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'label'],\n    num_rows: 119757\n})"},"metadata":{}}]},{"cell_type":"code","source":"df_train, df_test = train_test_split(df,test_size=None, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:53:45.265091Z","iopub.execute_input":"2024-03-24T21:53:45.265399Z","iopub.status.idle":"2024-03-24T21:53:45.289343Z","shell.execute_reply.started":"2024-03-24T21:53:45.265377Z","shell.execute_reply":"2024-03-24T21:53:45.288363Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\n# from pandas\ntrain_ds = Dataset.from_pandas(df_train)\ntest_ds = Dataset.from_pandas(df_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:53:45.290755Z","iopub.execute_input":"2024-03-24T21:53:45.294134Z","iopub.status.idle":"2024-03-24T21:53:45.927047Z","shell.execute_reply.started":"2024-03-24T21:53:45.294084Z","shell.execute_reply":"2024-03-24T21:53:45.926150Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import accuracy_score, roc_auc_score, f1_score\nimport numpy as np\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    \n    accuracy_val = accuracy_score(labels, predictions)\n    roc_auc_val = roc_auc_score(labels, predictions)\n    f1_score_val_macro = f1_score(labels, predictions, average = \"macro\")\n    f1_score_val_micro = f1_score(labels, predictions, average = \"micro\")\n    \n    return {\n        \"accuracy\": accuracy_val,\n        \"roc_auc\": roc_auc_val,\n        \"f1_score_val_macro\" : f1_score_val_macro,\n        \"f1_score_val_micro\" : f1_score_val_micro\n    }","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:55:50.547880Z","iopub.execute_input":"2024-03-24T21:55:50.548247Z","iopub.status.idle":"2024-03-24T21:55:50.560029Z","shell.execute_reply.started":"2024-03-24T21:55:50.548214Z","shell.execute_reply":"2024-03-24T21:55:50.559222Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nimport pandas as pd\nimport evaluate\nimport numpy as np\nfrom transformers import AutoModelForSequenceClassification, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorWithPadding, AutoTokenizer, set_seed, BitsAndBytesConfig\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom scipy.special import softmax\nimport argparse\nimport logging\nimport datetime\nimport bitsandbytes as bnb\nfrom peft import LoraConfig, PeftConfig, PeftModel, AutoPeftModelForCausalLM, TaskType, AutoPeftModelForSequenceClassification, prepare_model_for_kbit_training, get_peft_model\nfrom trl import SFTTrainer\nfrom datasets import disable_caching\nimport torch\nimport torch.nn.functional as F\n\ndisable_caching()\n\ndef preprocess_function(examples, **fn_kwargs):\n    return fn_kwargs['tokenizer'](examples[\"text\"], truncation=True)\n\n\ndef get_data(train_path, test_path, random_seed):\n    \"\"\"\n    function to read dataframe with columns\n    \"\"\"\n\n    train_df = pd.read_json(train_path, lines=True)\n    test_df = pd.read_json(test_path, lines=True)\n    \n    train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=random_seed)\n\n    return train_df, val_df, test_df\n\ndef compute_metrics(eval_pred):\n\n    f1_metric = evaluate.load(\"f1\")\n\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    \n    results = {}\n    results.update(f1_metric.compute(predictions=predictions, references = labels, average=\"micro\"))\n\n    return results\n\n\nclass CustomTrainer(Trainer):\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.pop(\"labels\")\n\n        # forward pass\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n\n        # compute custom loss\n        loss = F.binary_cross_entropy_with_logits(logits[:,1], labels.to(torch.float32))#, pos_weight=self.label_weights)\n        return (loss, outputs) if return_outputs else loss\n\ndef find_all_linear_names(model):\n    lora_module_names = set()\n    for name, module in model.named_modules():\n        if isinstance(module, bnb.nn.Linear4bit):\n            names = name.split(\".\")\n            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n\n    if \"lm_head\" in lora_module_names:  # needed for 16-bit\n        lora_module_names.remove(\"lm_head\")\n    return list(lora_module_names)\n\ndef fine_tune(train_df, valid_df, checkpoints_path, id2label, label2id, model):\n    checkpoints_path = \"abc\" + checkpoints_path\n    # pandas dataframe to huggingface Dataset\n    train_dataset = Dataset.from_pandas(train_df)\n    valid_dataset = Dataset.from_pandas(valid_df)\n    \n    train_dataset = Dataset.from_pandas(train_df)\n    valid_dataset = Dataset.from_pandas(valid_df)\n    \n    floatorbfloat = torch.float16\n    if 'lama' in model:\n        floatorbfloat = torch.bfloat16\n    \n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=floatorbfloat,\n    )\n    \n    tokenizer = AutoTokenizer.from_pretrained(model, trust_remote_code=True)\n    tokenizer.pad_token = tokenizer.eos_token\n    \n    model_name = model\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        quantization_config=bnb_config,\n        trust_remote_code=True,\n        num_labels=len(label2id), id2label=id2label, label2id=label2id\n    )\n    model.config.use_cache = False\n    \n    #DM added\n    if tokenizer.pad_token is None:\n      if tokenizer.eos_token is not None:\n        tokenizer.pad_token = tokenizer.eos_token\n      else:\n        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=32)\n    try:\n      model.config.pad_token_id = tokenizer.get_vocab()[tokenizer.pad_token]\n    except:\n      print(\"Warning: Exception occured while setting pad_token_id\")\n    \n    # tokenize data for train/valid\n    tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True, fn_kwargs={'tokenizer': tokenizer})\n    tokenized_valid_dataset = valid_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n    \n    lora_alpha = 16\n    lora_dropout = 0.1\n    lora_r = 64\n    \n    target_modules=[]\n    if 'falcon' in model_name:\n      target_modules=[\"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"]\n    elif 'mistral' in model_name:\n      target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj']\n    else:\n      target_modules=find_all_linear_names(model)\n    \n    peft_config = LoraConfig(\n        lora_alpha=lora_alpha,\n        lora_dropout=lora_dropout,\n        r=lora_r,\n        bias=\"none\",\n        task_type=TaskType.SEQ_CLS,\n        #task_type=\"CAUSAL_LM\",\n        target_modules=target_modules,\n        modules_to_save=[\"score\"]\n    )\n    \n    model.gradient_checkpointing_enable()\n    model = prepare_model_for_kbit_training(model)\n    model = get_peft_model(model, peft_config)\n    \n    output_dir = checkpoints_path + \"abc\"\n    per_device_train_batch_size = 16 #4\n    gradient_accumulation_steps = 4\n    optim = \"paged_adamw_32bit\"\n    save_steps = 1000 #10\n    logging_steps = 1000 #10\n    learning_rate = 2e-5 #2e-4\n    max_grad_norm = 0.3\n    max_steps = 10 #500\n    num_train_epochs=1 #added\n    warmup_ratio = 0.03\n    lr_scheduler_type = \"constant\"\n    fp16 = True\n    bf16 = False\n    \n    if 'lama' in model_name:\n        fp16 = False\n        bf16 = True\n    \n    training_arguments = TrainingArguments(\n        output_dir=output_dir,\n        per_device_train_batch_size=per_device_train_batch_size,\n        gradient_accumulation_steps=gradient_accumulation_steps,\n        optim=optim,\n        save_steps=save_steps,\n        logging_steps=logging_steps,\n        learning_rate=learning_rate,\n        fp16=fp16,\n        bf16=bf16,\n        max_grad_norm=max_grad_norm,\n        #max_steps=max_steps, #for testing\n        num_train_epochs=num_train_epochs,\n        warmup_ratio=warmup_ratio,\n        group_by_length=True,\n        lr_scheduler_type=lr_scheduler_type,\n        gradient_checkpointing=True,\n        load_best_model_at_end=True,\n        evaluation_strategy=\"steps\",\n    )\n    \n    max_seq_length = 512\n\n    trainer = CustomTrainer(\n        model=model,\n        train_dataset=tokenized_train_dataset,\n        eval_dataset=tokenized_valid_dataset,\n        #peft_config=peft_config,\n        #dataset_text_field=\"text\",\n        #max_seq_length=max_seq_length,\n        tokenizer=tokenizer,\n        args=training_arguments,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n\n    for name, module in trainer.model.named_modules():\n        if \"norm\" in name:\n            module = module.to(torch.float32)\n\n    trainer.train()\n\n    # save best model\n    best_model_path = checkpoints_path+'/best/'\n    \n    if not os.path.exists(best_model_path):\n        os.makedirs(best_model_path)\n    \n    trainer.save_model(best_model_path)\n    trainer.model.save_pretrained(best_model_path)\n    tokenizer.save_pretrained(best_model_path)\n#     torch.save(trainer.model.score.state_dict(), f'{best_model_path}/score-params.pt')\n    tokenized_train_dataset.cleanup_cache_files()\n    tokenized_valid_dataset.cleanup_cache_files()\n    \n    return #skip merging\n    print('Merging model...')\n    model_temp = AutoPeftModelForSequenceClassification.from_pretrained(\n    #model_temp = AutoPeftModelForCausalLM.from_pretrained(\n        best_model_path,\n        low_cpu_mem_usage=True,\n        torch_dtype=torch.float16,\n    )\n    model_temp = model_temp.merge_and_unload()        \n    model_temp.save_pretrained(\n       best_model_path, safe_serialization=True, max_shard_size=\"2GB\"\n    )\n\n\ndef test(test_df, model_path, id2label, label2id):\n    print('Loading model for predictions...')\n    tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n    \n    # load best model\n    model = AutoModelForSequenceClassification.from_pretrained(\n       model_path, trust_remote_code=True, num_labels=len(label2id),ignore_mismatched_sizes=True, id2label=id2label, label2id=label2id, torch_dtype=torch.float16\n    )\n    \n    #DM added\n    if tokenizer.pad_token is None:\n      if tokenizer.eos_token is not None:\n        tokenizer.pad_token = tokenizer.eos_token\n      else:\n        tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=32)\n    try:\n      model.config.pad_token_id = tokenizer.get_vocab()[tokenizer.pad_token]\n    except:\n      print(\"Warning: Exception occured while setting pad_token_id\")\n\n            \n    test_dataset = Dataset.from_pandas(test_df)\n\n    tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True,  fn_kwargs={'tokenizer': tokenizer})\n    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n    # create Trainer\n    trainer = Trainer(\n        model=model,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n    # get logits from predictions and evaluate results using classification report\n    predictions = trainer.predict(tokenized_test_dataset)\n    prob_pred = softmax(predictions.predictions, axis=-1)\n    preds = np.argmax(predictions.predictions, axis=-1)\n    metric = evaluate.load(\"bstrai/classification_report\")\n    results = metric.compute(predictions=preds, references=predictions.label_ids)\n    \n    # return dictionary of classification report\n    return results, preds, prob_pred\n\n\nif __name__ == '__main__':\n    random_seed = 0 \n    train_path =  \"/kaggle/input/reduced/downsampled_data.json\" # For example 'subtaskA_train_multilingual.jsonl'\n    test_path =  \"/kaggle/input/text-dataset/subtaskA_monolingual.jsonl\" # For example 'subtaskA_test_multilingual.jsonl'\n    model =  \"BAAI/bge-small-en-v1.5\" # For example 'xlm-roberta-base'\n    subtask =  'A' # For example 'A'\n    prediction_path = 'subtaskA_predictions.jsonl' # For example subtaskB_predictions.jsonl\n\n    if not os.path.exists(train_path):\n        logging.error(\"File doesnt exists: {}\".format(train_path))\n        raise ValueError(\"File doesnt exists: {}\".format(train_path))\n    \n    if not os.path.exists(test_path):\n        logging.error(\"File doesnt exists: {}\".format(train_path))\n        raise ValueError(\"File doesnt exists: {}\".format(train_path))\n    \n\n    if subtask == 'A':\n        id2label = {0: \"human\", 1: \"machine\"}\n        label2id = {\"human\": 0, \"machine\": 1}\n    elif subtask == 'B':\n        id2label = {0: 'human', 1: 'chatGPT', 2: 'cohere', 3: 'davinci', 4: 'bloomz', 5: 'dolly'}\n        label2id = {'human': 0, 'chatGPT': 1,'cohere': 2, 'davinci': 3, 'bloomz': 4, 'dolly': 5}\n    else:\n        logging.error(\"Wrong subtask: {}. It should be A or B\".format(train_path))\n        raise ValueError(\"Wrong subtask: {}. It should be A or B\".format(train_path))\n\n    set_seed(random_seed)\n\n    #get data for train/dev/test sets\n    train_df, valid_df, test_df = get_data(train_path, test_path, random_seed)\n    \n    # train detector model\n    fine_tune(train_df, valid_df, f\"{model}/subtask{subtask}/{random_seed}\", id2label, label2id, model)\n\n    # test detector model\n    results, predictions = test(test_df, f\"{model}/subtask{subtask}/{random_seed}/best/\", id2label, label2id)\n    \n    logging.info(results)\n    predictions_df = pd.DataFrame({'id': test_df['id'], 'label': predictions})\n    predictions_df.to_json(prediction_path, lines=True, orient='records')","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:55:50.561249Z","iopub.execute_input":"2024-03-24T21:55:50.561585Z","iopub.status.idle":"2024-03-24T22:35:10.879398Z","shell.execute_reply.started":"2024-03-24T21:55:50.561546Z","shell.execute_reply":"2024-03-24T22:35:10.877602Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/54.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01df6af107754dfc8c9735766eaca2ab"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240324_215625-3sojrq4l</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nlpeng/huggingface/runs/3sojrq4l' target=\"_blank\">cerulean-universe-3</a></strong> to <a href='https://wandb.ai/nlpeng/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nlpeng/huggingface' target=\"_blank\">https://wandb.ai/nlpeng/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nlpeng/huggingface/runs/3sojrq4l' target=\"_blank\">https://wandb.ai/nlpeng/huggingface/runs/3sojrq4l</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='44910' max='44910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [44910/44910 38:12, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Roc Auc</th>\n      <th>F1 Score Val Macro</th>\n      <th>F1 Score Val Micro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.231900</td>\n      <td>0.427842</td>\n      <td>0.899299</td>\n      <td>0.903312</td>\n      <td>0.899282</td>\n      <td>0.899299</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.532500</td>\n      <td>0.608526</td>\n      <td>0.880261</td>\n      <td>0.886130</td>\n      <td>0.880019</td>\n      <td>0.880261</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.002000</td>\n      <td>0.794878</td>\n      <td>0.869405</td>\n      <td>0.876045</td>\n      <td>0.868960</td>\n      <td>0.869405</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=44910, training_loss=0.22610588656753747, metrics={'train_runtime': 2357.6031, 'train_samples_per_second': 114.29, 'train_steps_per_second': 19.049, 'total_flos': 1981787910455808.0, 'train_loss': 0.22610588656753747, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"test_tokenized_ds","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:35:10.882870Z","iopub.execute_input":"2024-03-24T22:35:10.883779Z","iopub.status.idle":"2024-03-24T22:35:10.891666Z","shell.execute_reply.started":"2024-03-24T22:35:10.883750Z","shell.execute_reply":"2024-03-24T22:35:10.890573Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n    num_rows: 29940\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataTest = pd.read_json('/kaggle/input/testjson/subtaskA_monolingual.jsonl', lines = True)\ndf2 = dataTest[['text']]\ndf2 = df2.reset_index(drop=True)\ndf_test_ds = Dataset.from_pandas(df2)\ndf_test_tokenized_ds = df_test_ds.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:42:27.425149Z","iopub.execute_input":"2024-03-24T22:42:27.425541Z","iopub.status.idle":"2024-03-24T22:42:58.263332Z","shell.execute_reply.started":"2024-03-24T22:42:27.425511Z","shell.execute_reply":"2024-03-24T22:42:58.262081Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/35 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8e91f72cc6e433c9baebab62d98c5ae"}},"metadata":{}}]},{"cell_type":"code","source":"pred_output = trainer.predict(df_test_tokenized_ds)\nlogits = pred_output.predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:49:53.633356Z","iopub.execute_input":"2024-03-24T22:49:53.633757Z","iopub.status.idle":"2024-03-24T22:51:17.747961Z","shell.execute_reply.started":"2024-03-24T22:49:53.633718Z","shell.execute_reply":"2024-03-24T22:51:17.746792Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"prob_pred = softmax(logits, axis=-1)\npreds = np.argmax(logits, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:51:38.208566Z","iopub.execute_input":"2024-03-24T22:51:38.209332Z","iopub.status.idle":"2024-03-24T22:51:38.222339Z","shell.execute_reply.started":"2024-03-24T22:51:38.209298Z","shell.execute_reply":"2024-03-24T22:51:38.220935Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"metric1 = evaluate.load(\"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:51:41.773804Z","iopub.execute_input":"2024-03-24T22:51:41.774373Z","iopub.status.idle":"2024-03-24T22:51:42.096513Z","shell.execute_reply.started":"2024-03-24T22:51:41.774340Z","shell.execute_reply":"2024-03-24T22:51:42.095456Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"GoldDataset = pd.read_json('/kaggle/input/gs-dataset/subtaskA_monolingual_gs.jsonl', lines = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:51:47.363701Z","iopub.execute_input":"2024-03-24T22:51:47.364066Z","iopub.status.idle":"2024-03-24T22:51:48.112728Z","shell.execute_reply.started":"2024-03-24T22:51:47.364038Z","shell.execute_reply":"2024-03-24T22:51:48.111578Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"GoldDataset","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:51:51.898183Z","iopub.execute_input":"2024-03-24T22:51:51.899195Z","iopub.status.idle":"2024-03-24T22:51:51.919535Z","shell.execute_reply.started":"2024-03-24T22:51:51.899144Z","shell.execute_reply":"2024-03-24T22:51:51.916443Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                                    text  label     id\n0      Today, many adults or teenage drivers are hook...      0      0\n1      The automobile, since its advent, has revoluti...      1      1\n2       One policy that could potentially improve aca...      1      2\n3      Title: Navigating the Road Ahead: The Case for...      1      3\n4      Have you ever woken up in the morning and wish...      0      4\n...                                                  ...    ...    ...\n34267  There are many advantages of limiting car usag...      0  34267\n34268  When discussing the merits of the electoral co...      1  34268\n34269  In favor of student-designed summer assignment...      1  34269\n34270  No, FACE is not created by aliens. as a person...      0  34270\n34271   Distance learning has become a widely accepte...      1  34271\n\n[34272 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Today, many adults or teenage drivers are hook...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The automobile, since its advent, has revoluti...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>One policy that could potentially improve aca...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Title: Navigating the Road Ahead: The Case for...</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Have you ever woken up in the morning and wish...</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34267</th>\n      <td>There are many advantages of limiting car usag...</td>\n      <td>0</td>\n      <td>34267</td>\n    </tr>\n    <tr>\n      <th>34268</th>\n      <td>When discussing the merits of the electoral co...</td>\n      <td>1</td>\n      <td>34268</td>\n    </tr>\n    <tr>\n      <th>34269</th>\n      <td>In favor of student-designed summer assignment...</td>\n      <td>1</td>\n      <td>34269</td>\n    </tr>\n    <tr>\n      <th>34270</th>\n      <td>No, FACE is not created by aliens. as a person...</td>\n      <td>0</td>\n      <td>34270</td>\n    </tr>\n    <tr>\n      <th>34271</th>\n      <td>Distance learning has become a widely accepte...</td>\n      <td>1</td>\n      <td>34271</td>\n    </tr>\n  </tbody>\n</table>\n<p>34272 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"GoldDataset_labels = GoldDataset['label'].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:51:55.219705Z","iopub.execute_input":"2024-03-24T22:51:55.220455Z","iopub.status.idle":"2024-03-24T22:51:55.227292Z","shell.execute_reply.started":"2024-03-24T22:51:55.220422Z","shell.execute_reply":"2024-03-24T22:51:55.226066Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"metric_classification = evaluate.load(\"bstrai/classification_report\")\nresults = metric_classification.compute(predictions=preds, references=GoldDataset_labels)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:54:46.600134Z","iopub.execute_input":"2024-03-24T22:54:46.600545Z","iopub.status.idle":"2024-03-24T22:54:47.375490Z","shell.execute_reply.started":"2024-03-24T22:54:46.600513Z","shell.execute_reply":"2024-03-24T22:54:47.372158Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64d63fada3794d7da5e7b4750748f9a2"}},"metadata":{}},{"name":"stdout","text":"{'0': {'precision': 0.8992033542976939, 'recall': 0.6589847590953786, 'f1-score': 0.760577366386495, 'support': 16272}, '1': {'precision': 0.75168926477827, 'recall': 0.9332222222222222, 'f1-score': 0.8326765310927703, 'support': 18000}, 'accuracy': 0.8030170401493931, 'macro avg': {'precision': 0.825446309537982, 'recall': 0.7961034906588004, 'f1-score': 0.7966269487396327, 'support': 34272}, 'weighted avg': {'precision': 0.8217274669450553, 'recall': 0.8030170401493931, 'f1-score': 0.7984445747406311, 'support': 34272}}\n","output_type":"stream"}]},{"cell_type":"code","source":"f1_metric = evaluate.load(\"f1\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:52:05.676274Z","iopub.execute_input":"2024-03-24T22:52:05.676952Z","iopub.status.idle":"2024-03-24T22:52:06.138782Z","shell.execute_reply.started":"2024-03-24T22:52:05.676922Z","shell.execute_reply":"2024-03-24T22:52:06.137535Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a60cbecc5a84f91ade273335fb561f2"}},"metadata":{}}]},{"cell_type":"code","source":"results_f1_micro = f1_metric.compute(predictions=preds, references=GoldDataset_labels, average = \"micro\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:52:13.682593Z","iopub.execute_input":"2024-03-24T22:52:13.683509Z","iopub.status.idle":"2024-03-24T22:52:13.989470Z","shell.execute_reply.started":"2024-03-24T22:52:13.683477Z","shell.execute_reply":"2024-03-24T22:52:13.988167Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(results_f1_micro)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:52:16.870644Z","iopub.execute_input":"2024-03-24T22:52:16.871366Z","iopub.status.idle":"2024-03-24T22:52:16.879177Z","shell.execute_reply.started":"2024-03-24T22:52:16.871331Z","shell.execute_reply":"2024-03-24T22:52:16.877321Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"{'f1': 0.8030170401493932}\n","output_type":"stream"}]},{"cell_type":"code","source":"results_f1_macro = f1_metric.compute(predictions=preds, references=GoldDataset_labels, average = \"macro\")\nprint(results_f1_macro)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:52:19.817059Z","iopub.execute_input":"2024-03-24T22:52:19.817450Z","iopub.status.idle":"2024-03-24T22:52:20.140479Z","shell.execute_reply.started":"2024-03-24T22:52:19.817421Z","shell.execute_reply":"2024-03-24T22:52:20.138320Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"{'f1': 0.7966269487396327}\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy = metric1.compute(predictions=preds, references=GoldDataset_labels)\nprint(accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:52:24.506396Z","iopub.execute_input":"2024-03-24T22:52:24.506821Z","iopub.status.idle":"2024-03-24T22:52:24.783594Z","shell.execute_reply.started":"2024-03-24T22:52:24.506789Z","shell.execute_reply":"2024-03-24T22:52:24.782611Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"{'accuracy': 0.8030170401493931}\n","output_type":"stream"}]},{"cell_type":"code","source":"json_result_df = GoldDataset['id']","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:55:42.811372Z","iopub.execute_input":"2024-03-24T22:55:42.812149Z","iopub.status.idle":"2024-03-24T22:55:42.818522Z","shell.execute_reply.started":"2024-03-24T22:55:42.812101Z","shell.execute_reply":"2024-03-24T22:55:42.816951Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"json_result_df = json_result_df.to_frame()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:55:45.986253Z","iopub.execute_input":"2024-03-24T22:55:45.986646Z","iopub.status.idle":"2024-03-24T22:55:45.993475Z","shell.execute_reply.started":"2024-03-24T22:55:45.986615Z","shell.execute_reply":"2024-03-24T22:55:45.992305Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"json_result_df","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:56:09.979654Z","iopub.execute_input":"2024-03-24T22:56:09.980061Z","iopub.status.idle":"2024-03-24T22:56:09.996920Z","shell.execute_reply.started":"2024-03-24T22:56:09.980029Z","shell.execute_reply":"2024-03-24T22:56:09.995421Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"          id\n0          0\n1          1\n2          2\n3          3\n4          4\n...      ...\n34267  34267\n34268  34268\n34269  34269\n34270  34270\n34271  34271\n\n[34272 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34267</th>\n      <td>34267</td>\n    </tr>\n    <tr>\n      <th>34268</th>\n      <td>34268</td>\n    </tr>\n    <tr>\n      <th>34269</th>\n      <td>34269</td>\n    </tr>\n    <tr>\n      <th>34270</th>\n      <td>34270</td>\n    </tr>\n    <tr>\n      <th>34271</th>\n      <td>34271</td>\n    </tr>\n  </tbody>\n</table>\n<p>34272 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pred_df = pd.DataFrame({'label':preds})","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:56:18.379220Z","iopub.execute_input":"2024-03-24T22:56:18.379623Z","iopub.status.idle":"2024-03-24T22:56:18.386651Z","shell.execute_reply.started":"2024-03-24T22:56:18.379592Z","shell.execute_reply":"2024-03-24T22:56:18.385320Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"pred_df","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:56:27.247994Z","iopub.execute_input":"2024-03-24T22:56:27.248879Z","iopub.status.idle":"2024-03-24T22:56:27.263046Z","shell.execute_reply.started":"2024-03-24T22:56:27.248847Z","shell.execute_reply":"2024-03-24T22:56:27.261616Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"       label\n0          1\n1          1\n2          1\n3          1\n4          1\n...      ...\n34267      0\n34268      1\n34269      1\n34270      1\n34271      1\n\n[34272 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34267</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34268</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34269</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34270</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34271</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>34272 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"json_result_df_final = pd.concat([json_result_df, pred_df], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:56:34.922957Z","iopub.execute_input":"2024-03-24T22:56:34.923798Z","iopub.status.idle":"2024-03-24T22:56:34.931372Z","shell.execute_reply.started":"2024-03-24T22:56:34.923758Z","shell.execute_reply":"2024-03-24T22:56:34.929829Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"json_result_df_final","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:56:41.653008Z","iopub.execute_input":"2024-03-24T22:56:41.653748Z","iopub.status.idle":"2024-03-24T22:56:41.672039Z","shell.execute_reply.started":"2024-03-24T22:56:41.653715Z","shell.execute_reply":"2024-03-24T22:56:41.670803Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"          id  label\n0          0      1\n1          1      1\n2          2      1\n3          3      1\n4          4      1\n...      ...    ...\n34267  34267      0\n34268  34268      1\n34269  34269      1\n34270  34270      1\n34271  34271      1\n\n[34272 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34267</th>\n      <td>34267</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34268</th>\n      <td>34268</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34269</th>\n      <td>34269</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34270</th>\n      <td>34270</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34271</th>\n      <td>34271</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>34272 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:56:50.632375Z","iopub.execute_input":"2024-03-24T22:56:50.633511Z","iopub.status.idle":"2024-03-24T22:56:50.641285Z","shell.execute_reply.started":"2024-03-24T22:56:50.633475Z","shell.execute_reply":"2024-03-24T22:56:50.639923Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"json_result_df_final.to_json('json_predictions_peft_bge', orient='records', lines=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T22:58:23.391940Z","iopub.execute_input":"2024-03-24T22:58:23.392362Z","iopub.status.idle":"2024-03-24T22:58:23.452964Z","shell.execute_reply.started":"2024-03-24T22:58:23.392332Z","shell.execute_reply":"2024-03-24T22:58:23.451785Z"},"trusted":true},"execution_count":50,"outputs":[]}]}